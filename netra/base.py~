import logging
import os
from os.path import expanduser, join

import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
from tensorflow.python.framework import errors_impl


os.environ['TF_CPP_MIN_LOG_LEVEL']='2'


logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
logger.addHandler(logging.StreamHandler())


class Model:
    def __init__(self, name, input_nodes, output_nodes, learning_rate,
                 model_path=None):
        self.name = name
        self.inputs = tf.placeholder(tf.float32, [None, input_nodes])
        self.weights = tf.Variable(tf.zeros([input_nodes, output_nodes]),
                                   name='weights')
        self.bias = tf.Variable(tf.zeros([output_nodes]), name='bias')
        self.outputs = tf.placeholder(tf.float32, [None, output_nodes])
        self.learning_rate = learning_rate
        self.setup(model_path)

    def setup(self, model_path=None):
        if not model_path:
            model_path = join(self.cache_dir, 'model.default')
        self.model_path = model_path

        self.data = input_data.read_data_sets(self.cache_dir, one_hot=True)
        self.session = tf.Session()
        self.session.run(tf.global_variables_initializer())
        self.saver = tf.train.Saver([self.weights, self.bias])

    @property
    def cache_dir(self):
        return expanduser('~/.cache/tensorflow/{}/'.format(self.name))

    def feed_dict(self, inputs, outputs):
        return {self.inputs: inputs, self.outputs: outputs}

    @property
    def output(self):
        r_output = tf.matmul(self.inputs, self.weights) + self.bias
        output = tf.nn.softmax(r_output)
        return output

    def train(self, epochs=1000, batch_size=100):
        logger.info('Starting training')
        self.restore()
        cross_entropy = -tf.reduce_sum(self.outputs * tf.log(self.output))
        train_step = tf.train.GradientDescentOptimizer(
            self.learning_rate).minimize(cross_entropy)
        for _ in range(epochs):
            inputs, outputs = self.data.train.next_batch(batch_size)
            self.session.run(train_step,
                             feed_dict=self.feed_dict(inputs, outputs))
        prediction = tf.equal(tf.argmax(self.output, 1),
                              tf.argmax(self.outputs, 1))
        accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))
        data = self.feed_dict(self.data.test.images,
                              self.data.test.labels)
        accuracy_value = self.session.run(accuracy, feed_dict=data)
        logger.info('Accuracy: {}'.format(accuracy_value))
        logger.info('Completed training')
        self.save()

    def test(self, input_):
        return self.session.run(
            self.output, feed_dict={self.inputs: input_}).flatten().tolist()

    def restore(self):
        try:
            self.saver.restore(self.session, self.model_path)
            logger.info('Restored model from {}'.format(self.model_path))
        except errors_impl.NotFoundError:
            logger.info('No model to restore')

    def save(self):
        return self.saver.save(self.session, self.model_path)


# name = 'mnist_regression'
# input_nodes = 28 * 28
# output_nodes = 10
# learning_rate = 0.01

# mnist = Model(name, input_nodes, output_nodes, learning_rate)

# num_of_epochs = 1000
# batch_size = 100

# mnist.train(num_of_epochs, batch_size)

BaseModel = Model
